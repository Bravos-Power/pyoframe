import shutil
import gdown
import os
from urllib.request import urlretrieve
from pathlib import Path

CATS_GITHUB_URL = "https://raw.githubusercontent.com/WISPO-POP/CATS-CaliforniaTestSystem/f260d8bd89e68997bf12d24e767475b2f2b88a77/GIS/"

INPUT_DIR = Path("input_data/energy_planning")
RAW_INPUT_DIR = INPUT_DIR / "raw_inputs"
PROCESSED_INPUT_DIR = INPUT_DIR / "intermediary_inputs"
SCRIPTS_DIR = Path("./scripts")

rule generate_all_inputs:
    input:
        loads=PROCESSED_INPUT_DIR / "loads.parquet",
        lines=PROCESSED_INPUT_DIR / "lines_simplified.parquet",
        generators=PROCESSED_INPUT_DIR / "generators.parquet",
        yearly_limit=PROCESSED_INPUT_DIR / "yearly_limits.parquet",
        vcf=PROCESSED_INPUT_DIR / "variable_capacity_factors.parquet",
        bodf=PROCESSED_INPUT_DIR / "branch_outage_dist_facts.parquet",
    output:
        directory(INPUT_DIR / "final_inputs")
    run:
        output_dir = Path(output[0])
        os.makedirs(output_dir, exist_ok=True)
        for input_data in input:
            shutil.copy(input_data, output_dir / Path(input_data).name)


rule fetch_load_data:
    """Downloads the load data from the Google Drive folder hosted by the CATS project (https://drive.google.com/drive/folders/1Zo6ZeZ1OSjHCOWZybbTd6PgO4DQFs8_K)"""
    output:
        RAW_INPUT_DIR / "CATS_loads.csv",
    run:
        gdown.download(id="1Sz8st7g4Us6oijy1UYMPUvkA1XeZlIr8", output=output[0])


rule fetch_generation_data:
    """Downloads the generation data from the Google Drive folder hosted by the CATS project (https://drive.google.com/drive/folders/1Zo6ZeZ1OSjHCOWZybbTd6PgO4DQFs8_K)"""
    output:
        RAW_INPUT_DIR / "CATS_generation.csv",
    run:
        gdown.download(id="1CxLlcwAEUy-JvJQdAfVydJ1p9Ecot-4d", output=output[0])


rule fetch_line_data:
    output:
        RAW_INPUT_DIR / "CATS_lines.json",
    run:
        urlretrieve(CATS_GITHUB_URL + "CATS_lines.json", output[0])


rule fetch_generator_data:
    output:
        RAW_INPUT_DIR / "CATS_generators.csv",
    run:
        urlretrieve(CATS_GITHUB_URL + "CATS_gens.csv", output[0])


rule process_load_data:
    """Convert the load data to narrow format and keep only the active loads."""
    input:
        RAW_INPUT_DIR / "CATS_loads.csv",
    output:
        PROCESSED_INPUT_DIR / "loads.parquet",
    notebook:
        str(SCRIPTS_DIR / "process_load_data.py.ipynb")


rule process_line_data:
    """Convert from .json to .parquet and keep only relevant columns."""
    input:
        RAW_INPUT_DIR / "CATS_lines.json",
    output:
        PROCESSED_INPUT_DIR / "lines.parquet",
    notebook:
        str(SCRIPTS_DIR / "process_lines_json.py.ipynb")


rule process_generator_data:
    """Group the generators by type and bus."""
    input:
        RAW_INPUT_DIR / "CATS_generators.csv",
    output:
        PROCESSED_INPUT_DIR / "generators.parquet",
    notebook:
        str(SCRIPTS_DIR / "process_generator_data.py.ipynb")


rule compute_capacity_factors:
    """Use the hourly generation data to create capacity factors by fuel type."""
    input:
        gen_capacity=PROCESSED_INPUT_DIR / "generators.parquet",
        gen_dispatch=RAW_INPUT_DIR / "CATS_generation.csv",
    output:
        yearly_limit=PROCESSED_INPUT_DIR / "yearly_limits.parquet",
        vcf=PROCESSED_INPUT_DIR / "variable_capacity_factors.parquet",
    notebook:
        str(SCRIPTS_DIR / "compute_capacity_factors.py.ipynb")


rule simplify_network:
    input:
        lines=PROCESSED_INPUT_DIR / "lines.parquet",
        generators=PROCESSED_INPUT_DIR / "generators.parquet",
        loads=PROCESSED_INPUT_DIR / "loads.parquet",
    output:
        PROCESSED_INPUT_DIR / "lines_simplified.parquet",
    script:
        SCRIPTS_DIR / "simplify_network.py"

rule compute_ptdf:
    input:
        lines=PROCESSED_INPUT_DIR / "lines_simplified.parquet",
    output:
        PROCESSED_INPUT_DIR / "power_transfer_dist_facts.parquet",
    notebook:
        str(SCRIPTS_DIR / "compute_power_transfer_dist_facts.ipynb")

rule compute_bodf:
    input:
        lines=PROCESSED_INPUT_DIR / "lines_simplified.parquet",
        ptdf=PROCESSED_INPUT_DIR / "power_transfer_dist_facts.parquet",
    output:
        PROCESSED_INPUT_DIR / "branch_outage_dist_facts.parquet",
    notebook:
        str(SCRIPTS_DIR / "compute_branch_outage_dist_facts.ipynb")
